{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9350f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "# Remove: from google.colab.patches import cv2_imshow\n",
    "# If you want to display images in Jupyter, use:\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def cv2_imshow(img):\n",
    "    \"\"\"Display an image using matplotlib in Jupyter Notebook.\"\"\"\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05158bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_motorcyclists_rcnn(image, sess, image_tensor, detection_boxes, detection_scores, detection_classes, num_detections, min_score_thresh=0.5):\n",
    "    \"\"\"Detect motorcyclists using RCNN model\"\"\"\n",
    "    image_expanded = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    # Perform detection\n",
    "    (boxes, scores, classes, num) = sess.run(\n",
    "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "        feed_dict={image_tensor: image_expanded})\n",
    "    \n",
    "    # Process detections\n",
    "    boxes = np.squeeze(boxes)\n",
    "    scores = np.squeeze(scores)\n",
    "    classes = np.squeeze(classes)\n",
    "    \n",
    "    # Filter by score threshold\n",
    "    valid_detections = scores > min_score_thresh\n",
    "    filtered_boxes = boxes[valid_detections]\n",
    "    filtered_classes = classes[valid_detections]\n",
    "    \n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    im_height, im_width = image.shape[:2]\n",
    "    final_boxes = []\n",
    "    \n",
    "    for box in filtered_boxes:\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        left = int(xmin * im_width)\n",
    "        right = int(xmax * im_width)\n",
    "        top = int(ymin * im_height)\n",
    "        bottom = int(ymax * im_height)\n",
    "        final_boxes.append([left, top, right, bottom])\n",
    "    \n",
    "    return final_boxes\n",
    "\n",
    "def detect_helmets_yolov8(cropped_image, helmet_model, confidence_threshold=0.25):\n",
    "    \"\"\"Detect helmets in cropped motorcyclist image using YOLOv8\"\"\"\n",
    "    results = helmet_model(cropped_image, conf=confidence_threshold, verbose=False)\n",
    "    \n",
    "    helmet_detections = []\n",
    "    if len(results) > 0 and results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            class_id = int(box.cls.item())\n",
    "            confidence = box.conf.item()\n",
    "            bbox = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "            \n",
    "            helmet_detections.append({\n",
    "                'class_id': class_id,\n",
    "                'confidence': confidence,\n",
    "                'bbox': bbox,\n",
    "                'class_name': 'With Helmet' if class_id == 0 else 'Without Helmet'\n",
    "            })\n",
    "    \n",
    "    return helmet_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd21df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Motorcycle detection model loaded successfully!\n",
      "Helmet detection model loaded successfully!\n",
      "Video Info: 1280x720, 59 FPS, 220 frames\n",
      "Starting video processing...\n",
      "Processing frame 30/220\n",
      "Processing frame 60/220\n",
      "Processing frame 90/220\n",
      "Processing frame 120/220\n",
      "Processing frame 150/220\n",
      "Processing frame 180/220\n",
      "Processing frame 210/220\n",
      "Video processing completed!\n",
      "Total frames processed: 220\n",
      "Total no-helmet violations detected: 273\n",
      "Output video saved to: /Users/kushalgupta/Desktop/DeepLearning/datasets/output/output4.mp4\n",
      "Helmet detection on video completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def cv2_imshow(img):\n",
    "    \"\"\"Display an image using matplotlib in Jupyter Notebook.\"\"\"\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def initialize_models():\n",
    "    \"\"\"Initialize YOLO models for motorcycle and helmet detection\"\"\"\n",
    "    \n",
    "    # Load YOLOv8 model for motorcycle detection (pretrained COCO model)\n",
    "    motorcycle_model = YOLO('yolov8n.pt')  # This will auto-download if not available\n",
    "    print(\"Motorcycle detection model loaded successfully!\")\n",
    "    \n",
    "    # Load your trained YOLOv8 helmet detection model\n",
    "    helmet_model_path = r\"/Users/kushalgupta/Desktop/DeepLearning/yolov8n.pt\"  # Update this path\n",
    "    helmet_model = YOLO(helmet_model_path)\n",
    "    print(\"Helmet detection model loaded successfully!\")\n",
    "    \n",
    "    return motorcycle_model, helmet_model\n",
    "\n",
    "def detect_motorcycles_yolov8(image, motorcycle_model, confidence_threshold=0.5):\n",
    "    \"\"\"Detect motorcycles using YOLOv8\"\"\"\n",
    "    results = motorcycle_model(image, conf=confidence_threshold, verbose=False)\n",
    "    \n",
    "    motorcycle_boxes = []\n",
    "    if len(results) > 0 and results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            class_id = int(box.cls.item())\n",
    "            confidence = box.conf.item()\n",
    "            bbox = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "            \n",
    "            # Class 3 is 'motorcycle' in COCO dataset\n",
    "            # Class 0 is 'person' (we might also want to detect riders)\n",
    "            if class_id == 3:  # Motorcycle\n",
    "                left, top, right, bottom = bbox.astype(int)\n",
    "                motorcycle_boxes.append({\n",
    "                    'bbox': [left, top, right, bottom],\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "    \n",
    "    return motorcycle_boxes\n",
    "\n",
    "def detect_helmets_yolov8(cropped_image, helmet_model, confidence_threshold=0.25):\n",
    "    \"\"\"Detect helmets in cropped motorcyclist image using YOLOv8\"\"\"\n",
    "    results = helmet_model(cropped_image, conf=confidence_threshold, verbose=False)\n",
    "    \n",
    "    helmet_detections = []\n",
    "    if len(results) > 0 and results[0].boxes is not None:\n",
    "        for box in results[0].boxes:\n",
    "            class_id = int(box.cls.item())\n",
    "            confidence = box.conf.item()\n",
    "            bbox = box.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "            \n",
    "            helmet_detections.append({\n",
    "                'class_id': class_id,\n",
    "                'confidence': confidence,\n",
    "                'bbox': bbox,\n",
    "                'class_name': 'With Helmet' if class_id == 0 else 'Without Helmet'\n",
    "            })\n",
    "    \n",
    "    return helmet_detections\n",
    "\n",
    "def expand_bbox_for_rider(bbox, image_shape, expansion_factor=0.3):\n",
    "    \"\"\"Expand motorcycle bbox to include rider\"\"\"\n",
    "    left, top, right, bottom = bbox\n",
    "    height = bottom - top\n",
    "    width = right - left\n",
    "    \n",
    "    # Expand upwards to include rider\n",
    "    expanded_top = max(0, top - int(height * expansion_factor))\n",
    "    expanded_bottom = min(image_shape[0], bottom + int(height * 0.1))\n",
    "    expanded_left = max(0, left - int(width * 0.1))\n",
    "    expanded_right = min(image_shape[1], right + int(width * 0.1))\n",
    "    \n",
    "    return [expanded_left, expanded_top, expanded_right, expanded_bottom]\n",
    "\n",
    "def process_video(input_video_path, output_video_path, motorcycle_model, helmet_model):\n",
    "    \"\"\"Process video for helmet detection using only YOLOv8\"\"\"\n",
    "    \n",
    "    # Open input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video Info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_video_path), exist_ok=True)\n",
    "    \n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    no_helmet_count = 0\n",
    "    \n",
    "    print(\"Starting video processing...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "        \n",
    "        # Create a copy for drawing\n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # Step 1: Detect motorcycles using YOLOv8\n",
    "        motorcycle_boxes = detect_motorcycles_yolov8(frame, motorcycle_model)\n",
    "        \n",
    "        # Step 2: For each motorcycle, detect helmets using YOLOv8\n",
    "        for moto_box in motorcycle_boxes:\n",
    "            bbox = moto_box['bbox']\n",
    "            left, top, right, bottom = bbox\n",
    "            \n",
    "            # Draw motorcycle bounding box\n",
    "            cv2.rectangle(output_frame, (left, top), (right, bottom), (255, 0, 0), 2)\n",
    "            cv2.putText(output_frame, f\"Motorcycle: {moto_box['confidence']:.2f}\", \n",
    "                       (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "            \n",
    "            # Expand bbox to include rider area\n",
    "            rider_bbox = expand_bbox_for_rider(bbox, frame.shape)\n",
    "            rider_left, rider_top, rider_right, rider_bottom = rider_bbox\n",
    "            \n",
    "            # Draw expanded rider area (optional, for debugging)\n",
    "            cv2.rectangle(output_frame, (rider_left, rider_top), (rider_right, rider_bottom), \n",
    "                         (255, 165, 0), 1)  # Orange dashed line for rider area\n",
    "            \n",
    "            # Crop rider region\n",
    "            cropped_rider = frame[rider_top:rider_bottom, rider_left:rider_right]\n",
    "            \n",
    "            if cropped_rider.size > 0:\n",
    "                # Detect helmets in cropped region\n",
    "                helmet_detections = detect_helmets_yolov8(cropped_rider, helmet_model)\n",
    "                \n",
    "                has_helmet = False\n",
    "                has_no_helmet = False\n",
    "                \n",
    "                for detection in helmet_detections:\n",
    "                    # Convert helmet bbox coordinates from cropped to original image\n",
    "                    h_bbox = detection['bbox']\n",
    "                    h_left = int(h_bbox[0]) + rider_left\n",
    "                    h_top = int(h_bbox[1]) + rider_top\n",
    "                    h_right = int(h_bbox[2]) + rider_left\n",
    "                    h_bottom = int(h_bbox[3]) + rider_top\n",
    "                    \n",
    "                    # Choose color based on helmet detection\n",
    "                    if detection['class_name'] == 'With Helmet':\n",
    "                        color = (0, 255, 0)  # Green for helmet\n",
    "                        has_helmet = True\n",
    "                    else:\n",
    "                        color = (0, 0, 255)  # Red for no helmet\n",
    "                        has_no_helmet = True\n",
    "                        no_helmet_count += 1\n",
    "                    \n",
    "                    # Draw helmet bounding box\n",
    "                    cv2.rectangle(output_frame, (h_left, h_top), (h_right, h_bottom), color, 2)\n",
    "                    \n",
    "                    # Add label\n",
    "                    label = f\"{detection['class_name']}: {detection['confidence']:.2f}\"\n",
    "                    cv2.putText(output_frame, label, (h_left, h_top - 10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                \n",
    "                # Add motorcyclist status\n",
    "                if has_no_helmet:\n",
    "                    status = \"NO HELMET - VIOLATION\"\n",
    "                    status_color = (0, 0, 255)\n",
    "                elif has_helmet:\n",
    "                    status = \"HELMET DETECTED\"\n",
    "                    status_color = (0, 255, 0)\n",
    "                else:\n",
    "                    status = \"NO HELMET DETECTED\"\n",
    "                    status_color = (255, 255, 0)\n",
    "                \n",
    "                cv2.putText(output_frame, status, (left, top - 40),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, status_color, 2)\n",
    "        \n",
    "        # Add frame counter and statistics\n",
    "        cv2.putText(output_frame, f\"Frame: {frame_count}/{total_frames}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(output_frame, f\"No Helmet Violations: {no_helmet_count}\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        # Write frame to output video\n",
    "        out.write(output_frame)\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Video processing completed!\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Total no-helmet violations detected: {no_helmet_count}\")\n",
    "    print(f\"Output video saved to: {output_video_path}\")\n",
    "\n",
    "# Alternative: Direct helmet detection on full frame (simpler approach)\n",
    "def process_video_simple(input_video_path, output_video_path, helmet_model):\n",
    "    \"\"\"Simplified version - directly detect helmets in full frame\"\"\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_video_path}\")\n",
    "        return\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video Info: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_video_path), exist_ok=True)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    no_helmet_count = 0\n",
    "    \n",
    "    print(\"Starting simple video processing...\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Processing frame {frame_count}/{total_frames}\")\n",
    "        \n",
    "        output_frame = frame.copy()\n",
    "        \n",
    "        # Direct helmet detection on full frame\n",
    "        results = helmet_model(frame, conf=0.25, verbose=False)\n",
    "        \n",
    "        if len(results) > 0 and results[0].boxes is not None:\n",
    "            for box in results[0].boxes:\n",
    "                class_id = int(box.cls.item())\n",
    "                confidence = box.conf.item()\n",
    "                bbox = box.xyxy[0].cpu().numpy()\n",
    "                \n",
    "                left, top, right, bottom = bbox.astype(int)\n",
    "                \n",
    "                if class_id == 0:  # With Helmet\n",
    "                    color = (0, 255, 0)\n",
    "                    label = f\"With Helmet: {confidence:.2f}\"\n",
    "                else:  # Without Helmet\n",
    "                    color = (0, 0, 255)\n",
    "                    label = f\"Without Helmet: {confidence:.2f}\"\n",
    "                    no_helmet_count += 1\n",
    "                \n",
    "                cv2.rectangle(output_frame, (left, top), (right, bottom), color, 2)\n",
    "                cv2.putText(output_frame, label, (left, top - 10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "        # Add frame counter and statistics\n",
    "        cv2.putText(output_frame, f\"Frame: {frame_count}/{total_frames}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(output_frame, f\"No Helmet Violations: {no_helmet_count}\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        \n",
    "        out.write(output_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Simple video processing completed!\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Total no-helmet violations detected: {no_helmet_count}\")\n",
    "    print(f\"Output video saved to: {output_video_path}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Choose which approach to use:\n",
    "    \n",
    "    # Approach 1: Two-step detection (Motorcycle â†’ Helmet)\n",
    "    print(\"Loading models...\")\n",
    "    motorcycle_model, helmet_model = initialize_models()\n",
    "    \n",
    "    # Define input and output paths\n",
    "    input_video_path = r\"/Users/kushalgupta/Desktop/DeepLearning/datasets/input/input.mp4\"\n",
    "    output_video_path = r\"/Users/kushalgupta/Desktop/DeepLearning/datasets/output/output4.mp4\"\n",
    "    \n",
    "    # Option A: Use two-step detection\n",
    "    process_video(input_video_path, output_video_path, motorcycle_model, helmet_model)\n",
    "    \n",
    "    # Option B: Use simple direct detection (uncomment below)\n",
    "    # process_video_simple(input_video_path, output_video_path, helmet_model)\n",
    "    \n",
    "    print(\"Helmet detection on video completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
